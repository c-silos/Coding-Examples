{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08b13eb3-09b7-4dc2-ae13-04ce1a79d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abd8e8e8-775e-4fb9-904b-7dc54b77893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/christinsilos/Desktop/Deep Learning Practice/train\"\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 123\n",
    "EPOCHS = 15\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f38f2ec7-4886-43bd-8dd7-c3bdb2579135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Reproducibility\n",
    "# -----------------------\n",
    "def seed_all(seed=123):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_all(SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ec3c12-214f-4962-8ec7-239c318f000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Transforms (ResNet expects ImageNet-style normalization)\n",
    "# -----------------------\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "955dbff2-b460-4029-96a6-2e30d10bda52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['acne', 'eksim', 'herpes', 'panu', 'rosacea']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Dataset + split\n",
    "# -----------------------\n",
    "full_ds = datasets.ImageFolder(DATA_DIR, transform=train_tfms)\n",
    "class_names = full_ds.classes\n",
    "num_classes = len(class_names)\n",
    "assert num_classes == 5, f\"Expected 5 classes, found {num_classes}\"\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "n = len(full_ds)\n",
    "n_val = int(VAL_SPLIT * n)\n",
    "n_train = n - n_val\n",
    "\n",
    "train_ds, val_ds = random_split(\n",
    "    full_ds,\n",
    "    [n_train, n_val],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "# Important: swap validation transforms (no augmentation)\n",
    "val_ds.dataset.transform = val_tfms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39914a10-95e2-4995-956d-3b88a2b98e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts: {'acne': 242, 'eksim': 233, 'herpes': 249, 'panu': 229, 'rosacea': 243}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------\n",
    "# Imbalance handling: WeightedRandomSampler for TRAIN subset\n",
    "# -----------------------\n",
    "train_targets = [full_ds.targets[i] for i in train_ds.indices]\n",
    "class_counts = np.bincount(train_targets, minlength=num_classes)\n",
    "print(\"Train class counts:\", dict(zip(class_names, class_counts.tolist())))\n",
    "\n",
    "class_inv_freq = 1.0 / np.clip(class_counts, 1, None)\n",
    "sample_weights = [class_inv_freq[t] for t in train_targets]\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5f231a9-1fc9-428c-84c7-6e462682618a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/christinsilos/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████████████████████████████████| 44.7M/44.7M [00:01<00:00, 23.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Model: ResNet18 pretrained + new classification head\n",
    "# -----------------------\n",
    "# torchvision >= 0.13 uses \"weights=...\"\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "132abcf4-ab5d-44fc-88d8-e284fc4cd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Loss: class-weighted CrossEntropy (based on TRAIN subset)\n",
    "# (You can disable this if using sampler feels sufficient)\n",
    "# -----------------------\n",
    "train_counts = class_counts.astype(np.float32)\n",
    "ce_weights = (train_counts.sum() / np.clip(train_counts, 1, None))\n",
    "ce_weights = ce_weights / ce_weights.mean()  # normalize scale\n",
    "ce_weights = torch.tensor(ce_weights, dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=ce_weights)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78f6493f-e73e-4272-832d-ae121915308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Eval: macro F1\n",
    "# -----------------------\n",
    "@torch.no_grad()\n",
    "def evaluate_f1(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_true.append(y.cpu().numpy())\n",
    "\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_true = np.concatenate(all_true)\n",
    "\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    per_class_f1 = f1_score(y_true, y_pred, average=None)\n",
    "    return macro_f1, per_class_f1, y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18e8fb75-479a-4df4-89f1-01ab773db471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.5283 | val_macro_f1=0.7680\n",
      "  per-class F1: [0.7586 0.5275 0.844  0.9065 0.8036]\n",
      "Epoch 02 | train_loss=0.2232 | val_macro_f1=0.8604\n",
      "  per-class F1: [0.7967 0.8358 0.8713 0.9032 0.8947]\n",
      "Epoch 03 | train_loss=0.0846 | val_macro_f1=0.8911\n",
      "  per-class F1: [0.9256 0.8281 0.8545 0.9624 0.8846]\n",
      "Epoch 04 | train_loss=0.0407 | val_macro_f1=0.8839\n",
      "  per-class F1: [0.9217 0.8148 0.8119 0.9635 0.9074]\n",
      "Epoch 05 | train_loss=0.0523 | val_macro_f1=0.8926\n",
      "  per-class F1: [0.84   0.8872 0.8868 0.9429 0.906 ]\n",
      "Epoch 06 | train_loss=0.1071 | val_macro_f1=0.8762\n",
      "  per-class F1: [0.8908 0.7863 0.8929 0.9565 0.8545]\n",
      "Epoch 07 | train_loss=0.1194 | val_macro_f1=0.8882\n",
      "  per-class F1: [0.8908 0.8154 0.9072 0.9781 0.8496]\n",
      "Epoch 08 | train_loss=0.0482 | val_macro_f1=0.8999\n",
      "  per-class F1: [0.9649 0.7965 0.8644 0.9645 0.9091]\n",
      "Epoch 09 | train_loss=0.0168 | val_macro_f1=0.9315\n",
      "  per-class F1: [0.9464 0.896  0.9216 0.9784 0.9153]\n",
      "Epoch 10 | train_loss=0.0190 | val_macro_f1=0.9075\n",
      "  per-class F1: [0.9649 0.8333 0.8673 0.9645 0.9074]\n",
      "Epoch 11 | train_loss=0.0643 | val_macro_f1=0.8595\n",
      "  per-class F1: [0.9273 0.6931 0.887  0.9781 0.812 ]\n",
      "Epoch 12 | train_loss=0.0292 | val_macro_f1=0.9035\n",
      "  per-class F1: [0.9474 0.8448 0.8727 0.9577 0.8947]\n",
      "Epoch 13 | train_loss=0.0645 | val_macro_f1=0.8455\n",
      "  per-class F1: [0.8519 0.8    0.8172 0.964  0.7943]\n",
      "Epoch 14 | train_loss=0.0581 | val_macro_f1=0.9005\n",
      "  per-class F1: [0.9358 0.8421 0.8807 1.     0.844 ]\n",
      "Epoch 15 | train_loss=0.0362 | val_macro_f1=0.9174\n",
      "  per-class F1: [0.9655 0.8571 0.8842 0.9855 0.8947]\n",
      "\n",
      "Best val macro F1: 0.9315337404709476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        acne     0.9815    0.9138    0.9464        58\n",
      "       eksim     0.9180    0.8750    0.8960        64\n",
      "      herpes     0.9216    0.9216    0.9216        51\n",
      "        panu     0.9577    1.0000    0.9784        68\n",
      "     rosacea     0.8852    0.9474    0.9153        57\n",
      "\n",
      "    accuracy                         0.9329       298\n",
      "   macro avg     0.9328    0.9315    0.9315       298\n",
      "weighted avg     0.9338    0.9329    0.9327       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Training loop: pick best epoch by val macro F1\n",
    "# -----------------------\n",
    "best_f1 = -1.0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    val_macro_f1, val_per_class_f1, _, _ = evaluate_f1(model, val_loader, device)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | val_macro_f1={val_macro_f1:.4f}\")\n",
    "    print(\"  per-class F1:\", np.round(val_per_class_f1, 4))\n",
    "\n",
    "    if val_macro_f1 > best_f1:\n",
    "        best_f1 = val_macro_f1\n",
    "        best_state = deepcopy(model.state_dict())\n",
    "\n",
    "# Load best checkpoint\n",
    "model.load_state_dict(best_state)\n",
    "print(\"\\nBest val macro F1:\", best_f1)\n",
    "\n",
    "# Final report on validation set\n",
    "val_macro_f1, _, y_true, y_pred = evaluate_f1(model, val_loader, device)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71d8fd-a92a-4b3a-8543-2a753112b0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
